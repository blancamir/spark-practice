{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a DataFrame from a csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "import pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "#Create spark session\n",
    "spark = SparkSession.builder.appName(\"CSV to Dataset\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read the csv file with no indications\n",
    "df = spark.read.csv('C:/Users/usuario\\Documents\\Blanca\\Spark\\data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+--------------------+\n|                 _c0|\n+--------------------+\n|\"id_local\";\"id_di...|\n|\"285016136\";\"8\";\"...|\n|\"285016137\";\"8\";\"...|\n|\"285016140\";\"8\";\"...|\n|\"285016143\";\"8\";\"...|\n+--------------------+\nonly showing top 5 rows\n\n"
     ]
    }
   ],
   "source": [
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "root\n |-- _c0: string (nullable = true)\n\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+----------------------+\n|WAR AND PEACE         |\n+----------------------+\n|By Leo Tolstoy/Tolstoi|\n|CONTENTS              |\n|BOOK ONE: 1805        |\n|CHAPTER I             |\n|CHAPTER II            |\n+----------------------+\nonly showing top 5 rows\n\n"
     ]
    }
   ],
   "source": [
    "#Read the csv file with options\n",
    "df2 = spark.read.options(delimiter= ',', header= 'True', inferSchema= 'True') \\\n",
    "        .csv('C:/Users/usuario\\Documents\\Blanca\\Spark\\data')\n",
    "    \n",
    "df2.show(5, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "root\n |-- WAR AND PEACE: string (nullable = true)\n\n"
     ]
    }
   ],
   "source": [
    "df2.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading csv files with specific custom schemas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType, FloatType, DoubleType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "root\n |-- name: string (nullable = true)\n |-- local_code: string (nullable = true)\n |-- category: string (nullable = true)\n\n+----+-------------+----------------------------------+\n|name|local_code   |category                          |\n+----+-------------+----------------------------------+\n|00A |heliport     |Total Rf Heliport                 |\n|00AK|small_airport|Lowell Field                      |\n|00AL|small_airport|Epps Airpark                      |\n|00AR|heliport     |Newport Hospital & Clinic Heliport|\n|00AZ|small_airport|Cordes Airport                    |\n|00CA|small_airport|Goldstone /Gts/ Airport           |\n|00CO|small_airport|Cass Field                        |\n|00FA|small_airport|Grass Patch Airport               |\n|00FD|heliport     |Ringhaver Heliport                |\n|00FL|small_airport|River Oak Airport                 |\n|00GA|small_airport|Lt World Airport                  |\n|00GE|heliport     |Caffrey Heliport                  |\n|00HI|heliport     |Kaupulehu Heliport                |\n|00ID|small_airport|Delta Shores Airport              |\n|00II|heliport     |Bailey Generation Station Heliport|\n|00IL|small_airport|Hammer Airport                    |\n|00IN|heliport     |St Mary Medical Center Heliport   |\n|00IS|small_airport|Hayenga's Cant Find Farms Airport |\n|00KS|small_airport|Hayden Farm Airport               |\n|00KY|small_airport|Robbins Roost Airport             |\n+----+-------------+----------------------------------+\nonly showing top 20 rows\n\n"
     ]
    }
   ],
   "source": [
    "schema = StructType() \\\n",
    "        .add('name', StringType(), True).add('local_code', StringType(), True) \\\n",
    "            .add('category', StringType(), True)\n",
    "\n",
    "df3 = spark.read.csv('C:/Users/usuario\\Documents\\Blanca\\Spark/practica_pyspark/airport_codes.csv', schema=schema, header=True)\n",
    "df3.printSchema()\n",
    "df3.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}