{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Machine Learning model with PySpark\n",
    "\n",
    "Prediction Boston housing prices\n",
    "\n",
    "The goal is to come up with a model to predict median value of a given house in the area."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "Boston housing dataset:\n",
    "\n",
    "CRIM — per capita crime rate by town.\n",
    "\n",
    "ZN — proportion of residential land zoned for lots over 25,000 sq.ft.\n",
    "\n",
    "INDUS — proportion of non-retail business acres per town.\n",
    "\n",
    "CHAS — Charles River dummy variable (= 1 if tract bounds river; 0 otherwise).\n",
    "\n",
    "NOX — nitrogen oxides concentration (parts per 10 million).\n",
    "\n",
    "RM — average number of rooms per dwelling.\n",
    "\n",
    "AGE — proportion of owner-occupied units built prior to 1940.\n",
    "\n",
    "DIS — weighted mean of distances to five Boston employment centres.\n",
    "\n",
    "RAD — index of accessibility to radial highways.\n",
    "\n",
    "TAX — full-value property-tax rate per $10,000.\n",
    "\n",
    "PTRATIO — pupil-teacher ratio by town.\n",
    "\n",
    "BLACK — 1000(Bk — 0.63)² where Bk is the proportion of blacks by town.\n",
    "\n",
    "LSTAT — lower status of the population (percent).\n",
    "\n",
    "MEDV — median value of owner-occupied homes in $1000s. This is the target variable."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "\n",
    "import pyspark\n",
    "import pyspark.sql.functions as pyf\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType, FloatType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create the spark session\n",
    "\n",
    "spark = SparkSession.builder.appName('boston_practice').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x19e17cf9e88>"
      ],
      "text/html": "\n            <div>\n                <p><b>SparkSession - in-memory</b></p>\n                \n        <div>\n            <p><b>SparkContext</b></p>\n\n            <p><a href=\"http://DESKTOP-DHHLRED:4040\">Spark UI</a></p>\n\n            <dl>\n              <dt>Version</dt>\n                <dd><code>v3.0.1</code></dd>\n              <dt>Master</dt>\n                <dd><code>local[*]</code></dd>\n              <dt>AppName</dt>\n                <dd><code>boston_practice</code></dd>\n            </dl>\n        </div>\n        \n            </div>\n        "
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "source": [
    "LOAD THE DATA"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+-------+---+-----+----+-----+-----+----+------+---+---+-------+------+-----+----+\n|   CRIM| ZN|INDUS|CHAS|  NOX|   RM| AGE|   DIS|RAD|TAX|PTRATIO|     B|LSTAT|MEDV|\n+-------+---+-----+----+-----+-----+----+------+---+---+-------+------+-----+----+\n|0.00632| 18| 2.31|   0|0.538|6.575|65.2|  4.09|  1|296|   15.3| 396.9| 4.98|24.0|\n|0.02731|  0| 7.07|   0|0.469|6.421|78.9|4.9671|  2|242|   17.8| 396.9| 9.14|21.6|\n|0.02729|  0| 7.07|   0|0.469|7.185|61.1|4.9671|  2|242|   17.8|392.83| 4.03|34.7|\n+-------+---+-----+----+-----+-----+----+------+---+---+-------+------+-----+----+\nonly showing top 3 rows\n\n"
     ]
    }
   ],
   "source": [
    "boston_df = spark.read.csv('housingData.csv', header=True, inferSchema=True)\n",
    "boston_df.show(3)"
   ]
  },
  {
   "source": [
    "DATA EXPLORATION"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "root\n |-- CRIM: string (nullable = true)\n |-- ZN: string (nullable = true)\n |-- INDUS: string (nullable = true)\n |-- CHAS: string (nullable = true)\n |-- NOX: double (nullable = true)\n |-- RM: double (nullable = true)\n |-- AGE: string (nullable = true)\n |-- DIS: double (nullable = true)\n |-- RAD: integer (nullable = true)\n |-- TAX: integer (nullable = true)\n |-- PTRATIO: double (nullable = true)\n |-- B: double (nullable = true)\n |-- LSTAT: string (nullable = true)\n |-- MEDV: double (nullable = true)\n\n"
     ]
    }
   ],
   "source": [
    "boston_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Covert string to float by casting\n",
    "\n",
    "boston_df = boston_df.withColumn('AGE', pyf.col('AGE').cast(IntegerType())) \\\n",
    "                    .withColumn('LSTAT', pyf.col('LSTAT').cast(FloatType())) \\\n",
    "                    .withColumn('INDUS', pyf.col('INDUS').cast(FloatType())) \\\n",
    "                    .withColumn('CRIM', pyf.col('CRIM').cast(FloatType())) \\\n",
    "                    .withColumn('ZN', pyf.col('ZN').cast(IntegerType())) \\\n",
    "                    .withColumn('CHAS', pyf.col('CHAS').cast(IntegerType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "root\n |-- CRIM: float (nullable = true)\n |-- ZN: integer (nullable = true)\n |-- INDUS: float (nullable = true)\n |-- CHAS: integer (nullable = true)\n |-- NOX: double (nullable = true)\n |-- RM: double (nullable = true)\n |-- AGE: integer (nullable = true)\n |-- DIS: double (nullable = true)\n |-- RAD: integer (nullable = true)\n |-- TAX: integer (nullable = true)\n |-- PTRATIO: double (nullable = true)\n |-- B: double (nullable = true)\n |-- LSTAT: float (nullable = true)\n |-- MEDV: double (nullable = true)\n |-- float: double (nullable = true)\n\n"
     ]
    }
   ],
   "source": [
    "boston_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "()\n"
     ]
    }
   ],
   "source": [
    "#Dimensions of the dataset\n",
    "print(np.shape(boston_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 506 entries, 0 to 505\nData columns (total 15 columns):\n #   Column   Non-Null Count  Dtype  \n---  ------   --------------  -----  \n 0   CRIM     486 non-null    float32\n 1   ZN       486 non-null    float64\n 2   INDUS    486 non-null    float32\n 3   CHAS     486 non-null    float64\n 4   NOX      506 non-null    float64\n 5   RM       506 non-null    float64\n 6   AGE      486 non-null    float64\n 7   DIS      506 non-null    float64\n 8   RAD      506 non-null    int32  \n 9   TAX      506 non-null    int32  \n 10  PTRATIO  506 non-null    float64\n 11  B        506 non-null    float64\n 12  LSTAT    486 non-null    float32\n 13  MEDV     506 non-null    float64\n 14  float    486 non-null    float64\ndtypes: float32(3), float64(10), int32(2)\nmemory usage: 49.5 KB\n"
     ]
    }
   ],
   "source": [
    "boston_df.toPandas().info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+----+---+-----+----+---+---+---+---+---+---+-------+---+-----+----+-----+\n|CRIM| ZN|INDUS|CHAS|NOX| RM|AGE|DIS|RAD|TAX|PTRATIO|  B|LSTAT|MEDV|float|\n+----+---+-----+----+---+---+---+---+---+---+-------+---+-----+----+-----+\n|  20| 20|   20|  20|  0|  0| 20|  0|  0|  0|      0|  0|   20|   0|   20|\n+----+---+-----+----+---+---+---+---+---+---+-------+---+-----+----+-----+\n\n"
     ]
    }
   ],
   "source": [
    "#Null and Nan values\n",
    "\n",
    "boston_df.select([pyf.count(pyf.when(pyf.isnan(c) | pyf.col(c).isNull(), c)).alias(c) for c in boston_df.columns]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove null values (4% of the total dataset), we still have enough data for the model.\n",
    "\n",
    "boston_df = boston_df.na.drop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "         count        mean         std        min         25%        50%  \\\n",
       "CRIM     394.0    3.690136    9.202422    0.00632    0.081955    0.26888   \n",
       "ZN       394.0   11.444162   23.941578    0.00000    0.000000    0.00000   \n",
       "INDUS    394.0   11.000878    6.908369    0.46000    5.130000    8.56000   \n",
       "CHAS     394.0    0.068528    0.252971    0.00000    0.000000    0.00000   \n",
       "NOX      394.0    0.553215    0.113112    0.38900    0.453000    0.53800   \n",
       "RM       394.0    6.280015    0.697985    3.56100    5.879250    6.20150   \n",
       "AGE      394.0   68.497462   27.953911    2.00000   45.000000   77.00000   \n",
       "DIS      394.0    3.805268    2.098571    1.12960    2.110100    3.19920   \n",
       "RAD      394.0    9.403553    8.633451    1.00000    4.000000    5.00000   \n",
       "TAX      394.0  406.431472  168.312419  187.00000  280.250000  330.00000   \n",
       "PTRATIO  394.0   18.537563    2.166460   12.60000   17.400000   19.10000   \n",
       "B        394.0  358.490939   89.283295    2.60000  376.707500  392.19000   \n",
       "LSTAT    394.0   12.769114    7.308430    1.73000    7.125000   11.30000   \n",
       "MEDV     394.0   22.359645    9.142979    5.00000   16.800000   21.05000   \n",
       "float    394.0   11.000863    6.908364    0.46000    5.130000    8.56000   \n",
       "\n",
       "                75%         max  \n",
       "CRIM       3.435973   88.976196  \n",
       "ZN        12.000000  100.000000  \n",
       "INDUS     18.100000   27.740000  \n",
       "CHAS       0.000000    1.000000  \n",
       "NOX        0.624000    0.871000  \n",
       "RM         6.605500    8.780000  \n",
       "AGE       94.000000  100.000000  \n",
       "DIS        5.116700   12.126500  \n",
       "RAD       24.000000   24.000000  \n",
       "TAX      666.000000  711.000000  \n",
       "PTRATIO   20.200000   22.000000  \n",
       "B        396.900000  396.900000  \n",
       "LSTAT     17.117501   37.970001  \n",
       "MEDV      25.000000   50.000000  \n",
       "float     18.100000   27.740000  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>count</th>\n      <th>mean</th>\n      <th>std</th>\n      <th>min</th>\n      <th>25%</th>\n      <th>50%</th>\n      <th>75%</th>\n      <th>max</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>CRIM</th>\n      <td>394.0</td>\n      <td>3.690136</td>\n      <td>9.202422</td>\n      <td>0.00632</td>\n      <td>0.081955</td>\n      <td>0.26888</td>\n      <td>3.435973</td>\n      <td>88.976196</td>\n    </tr>\n    <tr>\n      <th>ZN</th>\n      <td>394.0</td>\n      <td>11.444162</td>\n      <td>23.941578</td>\n      <td>0.00000</td>\n      <td>0.000000</td>\n      <td>0.00000</td>\n      <td>12.000000</td>\n      <td>100.000000</td>\n    </tr>\n    <tr>\n      <th>INDUS</th>\n      <td>394.0</td>\n      <td>11.000878</td>\n      <td>6.908369</td>\n      <td>0.46000</td>\n      <td>5.130000</td>\n      <td>8.56000</td>\n      <td>18.100000</td>\n      <td>27.740000</td>\n    </tr>\n    <tr>\n      <th>CHAS</th>\n      <td>394.0</td>\n      <td>0.068528</td>\n      <td>0.252971</td>\n      <td>0.00000</td>\n      <td>0.000000</td>\n      <td>0.00000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>NOX</th>\n      <td>394.0</td>\n      <td>0.553215</td>\n      <td>0.113112</td>\n      <td>0.38900</td>\n      <td>0.453000</td>\n      <td>0.53800</td>\n      <td>0.624000</td>\n      <td>0.871000</td>\n    </tr>\n    <tr>\n      <th>RM</th>\n      <td>394.0</td>\n      <td>6.280015</td>\n      <td>0.697985</td>\n      <td>3.56100</td>\n      <td>5.879250</td>\n      <td>6.20150</td>\n      <td>6.605500</td>\n      <td>8.780000</td>\n    </tr>\n    <tr>\n      <th>AGE</th>\n      <td>394.0</td>\n      <td>68.497462</td>\n      <td>27.953911</td>\n      <td>2.00000</td>\n      <td>45.000000</td>\n      <td>77.00000</td>\n      <td>94.000000</td>\n      <td>100.000000</td>\n    </tr>\n    <tr>\n      <th>DIS</th>\n      <td>394.0</td>\n      <td>3.805268</td>\n      <td>2.098571</td>\n      <td>1.12960</td>\n      <td>2.110100</td>\n      <td>3.19920</td>\n      <td>5.116700</td>\n      <td>12.126500</td>\n    </tr>\n    <tr>\n      <th>RAD</th>\n      <td>394.0</td>\n      <td>9.403553</td>\n      <td>8.633451</td>\n      <td>1.00000</td>\n      <td>4.000000</td>\n      <td>5.00000</td>\n      <td>24.000000</td>\n      <td>24.000000</td>\n    </tr>\n    <tr>\n      <th>TAX</th>\n      <td>394.0</td>\n      <td>406.431472</td>\n      <td>168.312419</td>\n      <td>187.00000</td>\n      <td>280.250000</td>\n      <td>330.00000</td>\n      <td>666.000000</td>\n      <td>711.000000</td>\n    </tr>\n    <tr>\n      <th>PTRATIO</th>\n      <td>394.0</td>\n      <td>18.537563</td>\n      <td>2.166460</td>\n      <td>12.60000</td>\n      <td>17.400000</td>\n      <td>19.10000</td>\n      <td>20.200000</td>\n      <td>22.000000</td>\n    </tr>\n    <tr>\n      <th>B</th>\n      <td>394.0</td>\n      <td>358.490939</td>\n      <td>89.283295</td>\n      <td>2.60000</td>\n      <td>376.707500</td>\n      <td>392.19000</td>\n      <td>396.900000</td>\n      <td>396.900000</td>\n    </tr>\n    <tr>\n      <th>LSTAT</th>\n      <td>394.0</td>\n      <td>12.769114</td>\n      <td>7.308430</td>\n      <td>1.73000</td>\n      <td>7.125000</td>\n      <td>11.30000</td>\n      <td>17.117501</td>\n      <td>37.970001</td>\n    </tr>\n    <tr>\n      <th>MEDV</th>\n      <td>394.0</td>\n      <td>22.359645</td>\n      <td>9.142979</td>\n      <td>5.00000</td>\n      <td>16.800000</td>\n      <td>21.05000</td>\n      <td>25.000000</td>\n      <td>50.000000</td>\n    </tr>\n    <tr>\n      <th>float</th>\n      <td>394.0</td>\n      <td>11.000863</td>\n      <td>6.908364</td>\n      <td>0.46000</td>\n      <td>5.130000</td>\n      <td>8.56000</td>\n      <td>18.100000</td>\n      <td>27.740000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 72
    }
   ],
   "source": [
    "#Summarize the data\n",
    "\n",
    "boston_df.toPandas().describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Correlation to MEDV for  CRIM -0.39723005782332804\n",
      "Correlation to MEDV for  ZN 0.40693969685738496\n",
      "Correlation to MEDV for  INDUS -0.5108291685843283\n",
      "Correlation to MEDV for  CHAS 0.1737011531689263\n",
      "Correlation to MEDV for  NOX -0.4590543298280346\n",
      "Correlation to MEDV for  RM 0.7239507648415225\n",
      "Correlation to MEDV for  AGE -0.4075902875077575\n",
      "Correlation to MEDV for  DIS 0.27954692634758843\n",
      "Correlation to MEDV for  RAD -0.41663770616487195\n",
      "Correlation to MEDV for  TAX -0.508864272782685\n",
      "Correlation to MEDV for  PTRATIO -0.5438090137802115\n",
      "Correlation to MEDV for  B 0.34725608800793734\n",
      "Correlation to MEDV for  LSTAT -0.7434496284723267\n",
      "Correlation to MEDV for  MEDV 1.0\n",
      "Correlation to MEDV for  float -0.5108291616632262\n"
     ]
    }
   ],
   "source": [
    "#Find correlation between independent variables and target variable (MEDV). When it is close to 1, it means that there is a strong positive correlation.\n",
    "\n",
    "import six\n",
    "for i in boston_df.columns:\n",
    "    if not(isinstance(boston_df.select(i).take(1)[0][0], six.string_types)):\n",
    "        print(\"Correlation to MEDV for \", i, boston_df.stat.corr('MEDV',i))"
   ]
  },
  {
   "source": [
    "In this case, the MEDV tends to goes up when the number of rooms (RM) goes up. "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "Prepare the data for a ML models. We need only two columns: features and labels (MEDV)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+--------------------+----+\n|            features|MEDV|\n+--------------------+----+\n|[18.0,2.309999942...|24.0|\n|[0.0,7.0700001716...|21.6|\n|[0.0,7.0700001716...|34.7|\n+--------------------+----+\nonly showing top 3 rows\n\n"
     ]
    }
   ],
   "source": [
    "#Put all the features to Vector using VectorAssembler\n",
    "\n",
    "feature = VectorAssembler(inputCols=boston_df.columns[1:], outputCol='features')\n",
    "vector = feature.transform(boston_df)\n",
    "vector = vector.select(['features', 'MEDV'])\n",
    "vector.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split the data\n",
    "\n",
    "train_data, test_data = vector.randomSplit([.8, .2], seed=42)"
   ]
  },
  {
   "source": [
    "## LINEAR REGRESSION"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.regression import LinearRegression\n",
    "\n",
    "lr = LinearRegression(featuresCol='features', labelCol='MEDV', maxIter=10, regParam=0.3, elasticNetParam=0.8)\n",
    "lr_model = lr.fit(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Coefficients: [0.0,0.0,0.0,0.0,0.10091450582098951,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.9653771816148912,0.0]\nIntercept: 0.13524502107248254\n"
     ]
    }
   ],
   "source": [
    "print('Coefficients: ' + str(lr_model.coefficients))\n",
    "print('Intercept: ' + str(lr_model.intercept))"
   ]
  },
  {
   "source": [
    "Summarize the model over the training set and print out some metrics"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "RMSE: 0.27090760468703495\nr2: 0.9991174765392707\n"
     ]
    }
   ],
   "source": [
    "#Train data\n",
    "trainSumm = lr_model.summary\n",
    "print(\"RMSE: {0}\".format(trainSumm.rootMeanSquaredError))\n",
    "print(\"r2: {0}\".format(trainSumm.r2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+-------+------------------+\n|summary|              MEDV|\n+-------+------------------+\n|  count|               337|\n|   mean|22.215727002967373|\n| stddev| 9.132788040978575|\n|    min|               5.0|\n|    max|              50.0|\n+-------+------------------+\n\n"
     ]
    }
   ],
   "source": [
    "train_data.describe().show()"
   ]
  },
  {
   "source": [
    "RMSE measures the differences between predicted values by the model and the actual values. The smaller RMSE value is, the closer predicted and observed values are.\n",
    "\n",
    "However, RMSE alone is meaningless until we compare with the actual “MEDV” value, such as mean, min and max. After such comparison, our RMSE looks pretty good."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "R squared at 0.99 indicates that in our model, approximate 99% of the variability in “MEDV” can be explained using the model."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Predictions"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+-----------------+----+\n|       prediction|MEDV|\n+-----------------+----+\n|33.08504259874513|33.4|\n|36.75165942777694|37.2|\n|39.34085798704513|39.8|\n|38.30962109703834|38.7|\n+-----------------+----+\nonly showing top 4 rows\n\n"
     ]
    }
   ],
   "source": [
    "#Test data\n",
    "pred = lr_model.transform(test_data)\n",
    "pred.select('prediction', 'MEDV').show(4)"
   ]
  },
  {
   "source": [
    "Evaluate the model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import RegressionEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "R Squared on test data = 0.999179\n"
     ]
    }
   ],
   "source": [
    "evaluator = RegressionEvaluator(predictionCol='prediction', labelCol='MEDV', metricName='r2')\n",
    "print('R Squared on test data = %g' % evaluator.evaluate(pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "RMSE on test data = 0.262293\n"
     ]
    }
   ],
   "source": [
    "evaluator = RegressionEvaluator(predictionCol='prediction', labelCol='MEDV', metricName='rmse')\n",
    "print('RMSE on test data = %g' % evaluator.evaluate(pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ]
}